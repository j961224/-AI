# Classification

 : 데이터가 어느 범주에 해당하는지 판단하는 문제
 
 (예측으로 정답을 얼마나 맞혔는지에 대한 정확도를 측정 -> 분류 모델은 마지막 레이어의 활성화함수로 softmax를 사용)
 
 ## 1. 비지도 학습
 
   : 정답이 없는 학습으로 예시로 개인정보가 가려진 신용카드 사용 정보로 비슷한 유형의 구매자 군집을 분류하는 문제
 
 ## 2. 지도 학습
 
   : 정답이 있는 분류 문제로 이항 분류가 대표적입니다.
   
   ### 2-1. 이항 분류
   
    : 정답의 범주가 두 개인 분류 문제입니다.
    ex) 레드 와인과 화이ㅣ트 와인 두 죵류로 나눌 수 있다.
    
    - value_counts()함수로 tpye 속성에 존재하는 각 값의 수를 출력
   
 ## 3. Data Normalization
 
   : 데이터를 0과 1사이로 스케일 조정하는 방법
   (data-data.min())/(data.max()-data.min())
 
 ## 4. One-Hot-Encoding방식
 
   : to_categorical로 원 핫 인코딩 방식으로 변경, num_classes는 정답 클래스 개수이다.
   
 ## 5. softmax 함수
 
   : 출력값들을 자연로그의 밑인 e의 지수로 사용해 계산한 뒤 모두 더한 값으로 나눈다.
   
 ## 6. 손실 함수 categorical_crossentropy
 
   : 두 확률분포 사이의 교차 엔트로피로 손실의 일종의 값이기에 낮을 수록 좋은 값이다.
   
   ### 6-1. Entropy
     
     : 확률의 역수에 로그를 취한 값 -> 불확실한 정보를 숫자로 정량화하려는 노력이자 하나의 도구
     
     (확률의 역수를 취해주는 이유는 확률이 높은 사건일수록 정보량이 적다고 판단)
     
   
