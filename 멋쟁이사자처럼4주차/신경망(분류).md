# Sigmoid 함수

 : 선형 연산에서는 일단 범위에 제한이 없는 실숫값을 계산하되, 이를 확률값의 성질에 맞게 즉 0~1 사이의 값을 갖도록 변환해주는 비선형 활성화 함수
 
## Cross Entropy
  
 : 이진 판단 문제의 손실함수로 두가지 확률 분포로 **신경망의 예측값에 따른 확률 분포**와 **실제 결괏값에 따른 확률 분포** 사이의 각 확률 분포가 얼마나 다른지 표현(**두 확률분포가 서로 얼마나 다른지 나타내는 정량적 지표 역할 수행**)
 
 ![교차 엔프로피](https://user-images.githubusercontent.com/59636424/112999658-1a800f00-91aa-11eb-9d49-4217edef4683.png)
 
 -> 정보량을 제공하는 확률분포(-logpi)와 가중평균 계산에 사용되는 확률분포(pi)를 다르게 설정하여 정보량의 기댓값을 구하는 방식

 -> **틀릴 수 있는 정보를 가지고 구한 엔트로피** 즉 정보량이다.
 
 -> 딥러닝의 예측이 완전히 빗나가게 되면 교차 엔프로피 값은 무한대가 되지만 어느정도 학습되면 그 값은 엔프로피 값으로 수렴
 
## Sigmoid 함수의 정의

 ![sigmoid 정의](https://user-images.githubusercontent.com/59636424/112951458-56997c80-9176-11eb-9a81-554c3d0bf4e0.png)
 
 : 이 함수 그대로 쓰면 종종 오버플로우 문제가 발생한다!(x에 큰 음수가 들어올 경우)
 
 - 해결법!
 ![sigmoid 정의1](https://user-images.githubusercontent.com/59636424/112956322-4df77500-917b-11eb-81dc-04a9c00eafc1.png)
 
## Entropy

  : 확률 분포의 무질서도, 불확실성이나 정보 표현의 부담 정도
  
  ## 정보이론
  
   : 신호에 존재하는 정보의 양을 촉정하는 이론
    
   - Pi의 역수 관계를 이용하여 정보 엔프로피(정보량의 평균 - H)표현
    
   ![정보이용량](https://user-images.githubusercontent.com/59636424/112953370-65812e80-9178-11eb-8ff1-ee4d1bf3381f.png)
    
   : 정보 엔프로피는 어떤 확률 분포로 일어나는 사건을 표현하는데 필요한 정보량으로 표현한 것으로 **확률분포의 불확실성**을 뜻합니다.
  
  ## 시그모이드 함수의 교차 엔프로피 식(함수)
  
   -> 시그모이드와 시그모이드 교차 엔트로피 식에 음수나 양수의 입력값 모두 처리할 수 있는 하나의 식 필요
    
   (위의 sigmoid 함수에서 x가 음수일 때 발생하는 문제를 해결 -> 오버플로우 문제 해결)
    
   ![sigmoid 정의2](https://user-images.githubusercontent.com/59636424/112957324-497f8c00-917c-11eb-9c61-8e3587b225c5.png)
    
   ex) Pulsar Star 예측하는 문제
    
  ## 평가 지표
  
  - Accuracy의 한계로 인해 평가 지표
    
    1. 정밀도(precision)
    
      : 참으로 예측한 것중 정답이 참인 비율 ( TP/(TP+FP) )
    
    2. 재현율(recall)
    
      : 정답이 참인 것들 중에 참으로 예측한 비율 ( TP/(TP+FN) )
   
    -> 하지만 정밀도와 재현율 중 하나의 값 올리기 또한 쉽다.
    
    3. F1-score
      
      : 정밀도와 재현율의 조화평균
      
      ![f1 score](https://user-images.githubusercontent.com/59636424/112973306-2361e800-918c-11eb-8f01-7d17f2cbb266.png)
  
  - 선택 분류 문제
  
   : 몇 가지 정해진 후보 가운데 하나를 선택하여 답을 하는 문제
  
# Softmax

 : 다수의 후보 항목들에 대한 로짓값 벡터를 확률 분포 벡터로 변환해주는 비선형 비활성화 함수
 
 (기존 상대적 가능성 비율에서 확률값으로 전환시켜 주는 역할)
 
 ![시그모이드1](https://user-images.githubusercontent.com/59636424/115416905-2142f480-a233-11eb-8321-d74c540f3867.png)
 
 -> 기존의 시그모이드 함수는 문제가 있다.
 
 1. 제약이 없는 x가 들어오게 되면 값이 매우 커지게 되며 오버플로우 오류가 발생할 가능성이 생긴다.
 
 2. 모든 값이 절대값이 아주 큰 음수로 쏠리게 되면 분자와 분모가 모두 0에 수렴하게 되며 결과적으로 0으로 나눗셈을 진행하는 상황이 발생한다.
 
 -> 두 가지 문제점을 동시에 해결할 수 있는 방법으로 분자와 ㅁ분모에 e^(xk)를 나누는 방법을 사용한다.
 
 ![시그모이드2](https://user-images.githubusercontent.com/59636424/115417617-b940de00-a233-11eb-9149-11e1279c11e9.png)
 
# Softmax 교차 엔트로피

 -> 교차 엔트로피의 신경망의 연산결과를 통해 얻어진 로짓값 자체가 매우 작은 값을 갖게 된다면 자연스럽게 확률값이 매우 작아져 0에 가까운 값이 될 수 있는 문제가 생긴다.
 
 : 그래서 아주 작은 양수값을 도입한다.
 
 ![시그모이드3](https://user-images.githubusercontent.com/59636424/115419154-10937e00-a235-11eb-8d69-4ba8cc2adebe.png)
 
 -> 계산의 폭주를 막아준다.
 
 (Ex. faulty_steel_plates_분류 문제.ipynb)
 
 
